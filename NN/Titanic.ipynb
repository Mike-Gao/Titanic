{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "%run lib/cleandata.py\n",
    "%run lib/dnn_utils_v2.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(n_x, None))\n",
    "    Y = tf.placeholder(tf.float32, shape=(n_y, None))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "        \n",
    "    W1 = tf.get_variable(\"W1\", [50,8], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [50,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [35, 50], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [35, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1, 35], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                             \n",
    "    A1 = tf.nn.relu(Z1)                                             \n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                           \n",
    "    A2 = tf.nn.relu(Z2)                                            \n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                                           \n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         \n",
    "    (n_x, m) = X_train.shape                         \n",
    "    n_y = Y_train.shape[0]                           \n",
    "    costs = []                                     \n",
    "    \n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            _ , epoch_cost = sess.run([optimizer, cost], feed_dict = {X:X_train, Y:Y_train})\n",
    "            \n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.round(Z3), tf.round(Y))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9) (418, 9)\n"
     ]
    }
   ],
   "source": [
    "train,test = clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[1:,:]\n",
    "Y_train = train[:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train2 = np.subtract(np.zeros(Y_train.shape)+1,Y_train.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 418)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.183220\n",
      "Cost after epoch 100: 0.655480\n",
      "Cost after epoch 200: 0.552865\n",
      "Cost after epoch 300: 0.508811\n",
      "Cost after epoch 400: 0.480598\n",
      "Cost after epoch 500: 0.462102\n",
      "Cost after epoch 600: 0.449439\n",
      "Cost after epoch 700: 0.439936\n",
      "Cost after epoch 800: 0.432076\n",
      "Cost after epoch 900: 0.425063\n",
      "Cost after epoch 1000: 0.419262\n",
      "Cost after epoch 1100: 0.414582\n",
      "Cost after epoch 1200: 0.410474\n",
      "Cost after epoch 1300: 0.406277\n",
      "Cost after epoch 1400: 0.401987\n",
      "Cost after epoch 1500: 0.398216\n",
      "Cost after epoch 1600: 0.394824\n",
      "Cost after epoch 1700: 0.391976\n",
      "Cost after epoch 1800: 0.389241\n",
      "Cost after epoch 1900: 0.386788\n",
      "Cost after epoch 2000: 0.384463\n",
      "Cost after epoch 2100: 0.382344\n",
      "Cost after epoch 2200: 0.380369\n",
      "Cost after epoch 2300: 0.378437\n",
      "Cost after epoch 2400: 0.376528\n",
      "Cost after epoch 2500: 0.374583\n",
      "Cost after epoch 2600: 0.372753\n",
      "Cost after epoch 2700: 0.370992\n",
      "Cost after epoch 2800: 0.369220\n",
      "Cost after epoch 2900: 0.367494\n",
      "Cost after epoch 3000: 0.365810\n",
      "Cost after epoch 3100: 0.364131\n",
      "Cost after epoch 3200: 0.362477\n",
      "Cost after epoch 3300: 0.360796\n",
      "Cost after epoch 3400: 0.359061\n",
      "Cost after epoch 3500: 0.357286\n",
      "Cost after epoch 3600: 0.355617\n",
      "Cost after epoch 3700: 0.353996\n",
      "Cost after epoch 3800: 0.352370\n",
      "Cost after epoch 3900: 0.350752\n",
      "Cost after epoch 4000: 0.349161\n",
      "Cost after epoch 4100: 0.347620\n",
      "Cost after epoch 4200: 0.346105\n",
      "Cost after epoch 4300: 0.344558\n",
      "Cost after epoch 4400: 0.342982\n",
      "Cost after epoch 4500: 0.341435\n",
      "Cost after epoch 4600: 0.339905\n",
      "Cost after epoch 4700: 0.338433\n",
      "Cost after epoch 4800: 0.336962\n",
      "Cost after epoch 4900: 0.335519\n",
      "Cost after epoch 5000: 0.334079\n",
      "Cost after epoch 5100: 0.332686\n",
      "Cost after epoch 5200: 0.331301\n",
      "Cost after epoch 5300: 0.329951\n",
      "Cost after epoch 5400: 0.328636\n",
      "Cost after epoch 5500: 0.327359\n",
      "Cost after epoch 5600: 0.326122\n",
      "Cost after epoch 5700: 0.324892\n",
      "Cost after epoch 5800: 0.323684\n",
      "Cost after epoch 5900: 0.322486\n",
      "Cost after epoch 6000: 0.321338\n",
      "Cost after epoch 6100: 0.320238\n",
      "Cost after epoch 6200: 0.319172\n",
      "Cost after epoch 6300: 0.318160\n",
      "Cost after epoch 6400: 0.317184\n",
      "Cost after epoch 6500: 0.316244\n",
      "Cost after epoch 6600: 0.315340\n",
      "Cost after epoch 6700: 0.314471\n",
      "Cost after epoch 6800: 0.313644\n",
      "Cost after epoch 6900: 0.312818\n",
      "Cost after epoch 7000: 0.312023\n",
      "Cost after epoch 7100: 0.311232\n",
      "Cost after epoch 7200: 0.310387\n",
      "Cost after epoch 7300: 0.309596\n",
      "Cost after epoch 7400: 0.308803\n",
      "Cost after epoch 7500: 0.307980\n",
      "Cost after epoch 7600: 0.307186\n",
      "Cost after epoch 7700: 0.306382\n",
      "Cost after epoch 7800: 0.305528\n",
      "Cost after epoch 7900: 0.304745\n",
      "Cost after epoch 8000: 0.304011\n",
      "Cost after epoch 8100: 0.303325\n",
      "Cost after epoch 8200: 0.302678\n",
      "Cost after epoch 8300: 0.302069\n",
      "Cost after epoch 8400: 0.301481\n",
      "Cost after epoch 8500: 0.300915\n",
      "Cost after epoch 8600: 0.300365\n",
      "Cost after epoch 8700: 0.299850\n",
      "Cost after epoch 8800: 0.299353\n",
      "Cost after epoch 8900: 0.298882\n",
      "Cost after epoch 9000: 0.298425\n",
      "Cost after epoch 9100: 0.297987\n",
      "Cost after epoch 9200: 0.297569\n",
      "Cost after epoch 9300: 0.297158\n",
      "Cost after epoch 9400: 0.296738\n",
      "Cost after epoch 9500: 0.296353\n",
      "Cost after epoch 9600: 0.295989\n",
      "Cost after epoch 9700: 0.295654\n",
      "Cost after epoch 9800: 0.295349\n",
      "Cost after epoch 9900: 0.295063\n",
      "Cost after epoch 10000: 0.294789\n",
      "Cost after epoch 10100: 0.294517\n",
      "Cost after epoch 10200: 0.294258\n",
      "Cost after epoch 10300: 0.294011\n",
      "Cost after epoch 10400: 0.293776\n",
      "Cost after epoch 10500: 0.293554\n",
      "Cost after epoch 10600: 0.293341\n",
      "Cost after epoch 10700: 0.293143\n",
      "Cost after epoch 10800: 0.292955\n",
      "Cost after epoch 10900: 0.292774\n",
      "Cost after epoch 11000: 0.292603\n",
      "Cost after epoch 11100: 0.292440\n",
      "Cost after epoch 11200: 0.292290\n",
      "Cost after epoch 11300: 0.292137\n",
      "Cost after epoch 11400: 0.291994\n",
      "Cost after epoch 11500: 0.291860\n",
      "Cost after epoch 11600: 0.291726\n",
      "Cost after epoch 11700: 0.291604\n",
      "Cost after epoch 11800: 0.291488\n",
      "Cost after epoch 11900: 0.291376\n",
      "Cost after epoch 12000: 0.291269\n",
      "Cost after epoch 12100: 0.291165\n",
      "Cost after epoch 12200: 0.291066\n",
      "Cost after epoch 12300: 0.290971\n",
      "Cost after epoch 12400: 0.290880\n",
      "Cost after epoch 12500: 0.290795\n",
      "Cost after epoch 12600: 0.290705\n",
      "Cost after epoch 12700: 0.290624\n",
      "Cost after epoch 12800: 0.290546\n",
      "Cost after epoch 12900: 0.290471\n",
      "Cost after epoch 13000: 0.290400\n",
      "Cost after epoch 13100: 0.290329\n",
      "Cost after epoch 13200: 0.290263\n",
      "Cost after epoch 13300: 0.290203\n",
      "Cost after epoch 13400: 0.290145\n",
      "Cost after epoch 13500: 0.290085\n",
      "Cost after epoch 13600: 0.290031\n",
      "Cost after epoch 13700: 0.289975\n",
      "Cost after epoch 13800: 0.289925\n",
      "Cost after epoch 13900: 0.289883\n",
      "Cost after epoch 14000: 0.289832\n",
      "Cost after epoch 14100: 0.289781\n",
      "Cost after epoch 14200: 0.289742\n",
      "Cost after epoch 14300: 0.289699\n",
      "Cost after epoch 14400: 0.289654\n",
      "Cost after epoch 14500: 0.289619\n",
      "Cost after epoch 14600: 0.289581\n",
      "Cost after epoch 14700: 0.289541\n",
      "Cost after epoch 14800: 0.289507\n",
      "Cost after epoch 14900: 0.289476\n",
      "Cost after epoch 15000: 0.289443\n",
      "Cost after epoch 15100: 0.289415\n",
      "Cost after epoch 15200: 0.289382\n",
      "Cost after epoch 15300: 0.289355\n",
      "Cost after epoch 15400: 0.289327\n",
      "Cost after epoch 15500: 0.289300\n",
      "Cost after epoch 15600: 0.289272\n",
      "Cost after epoch 15700: 0.289250\n",
      "Cost after epoch 15800: 0.289224\n",
      "Cost after epoch 15900: 0.289202\n",
      "Cost after epoch 16000: 0.289180\n",
      "Cost after epoch 16100: 0.289155\n",
      "Cost after epoch 16200: 0.289135\n",
      "Cost after epoch 16300: 0.289116\n",
      "Cost after epoch 16400: 0.289096\n",
      "Cost after epoch 16500: 0.289074\n",
      "Cost after epoch 16600: 0.289056\n",
      "Cost after epoch 16700: 0.289040\n",
      "Cost after epoch 16800: 0.289020\n",
      "Cost after epoch 16900: 0.289003\n",
      "Cost after epoch 17000: 0.288986\n",
      "Cost after epoch 17100: 0.288973\n",
      "Cost after epoch 17200: 0.288958\n",
      "Cost after epoch 17300: 0.288944\n",
      "Cost after epoch 17400: 0.288927\n",
      "Cost after epoch 17500: 0.288911\n",
      "Cost after epoch 17600: 0.288900\n",
      "Cost after epoch 17700: 0.288886\n",
      "Cost after epoch 17800: 0.288876\n",
      "Cost after epoch 17900: 0.288863\n",
      "Cost after epoch 18000: 0.288846\n",
      "Cost after epoch 18100: 0.288839\n",
      "Cost after epoch 18200: 0.288824\n",
      "Cost after epoch 18300: 0.288811\n",
      "Cost after epoch 18400: 0.288804\n",
      "Cost after epoch 18500: 0.288790\n",
      "Cost after epoch 18600: 0.288778\n",
      "Cost after epoch 18700: 0.288771\n",
      "Cost after epoch 18800: 0.288760\n",
      "Cost after epoch 18900: 0.288749\n",
      "Cost after epoch 19000: 0.288742\n",
      "Cost after epoch 19100: 0.288733\n",
      "Cost after epoch 19200: 0.288722\n",
      "Cost after epoch 19300: 0.288712\n",
      "Cost after epoch 19400: 0.288707\n",
      "Cost after epoch 19500: 0.288695\n",
      "Cost after epoch 19600: 0.288687\n",
      "Cost after epoch 19700: 0.288681\n",
      "Cost after epoch 19800: 0.288672\n",
      "Cost after epoch 19900: 0.288667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f8855ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train2, X_test, num_epochs = 20000, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \n",
    "    Z = np.dot(W, A.astype(float)) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache\n",
    "  \n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n",
    "  \n",
    "def L_model_forward(X, parameters):\n",
    "    \n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "        \n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n",
    "  \n",
    "def predictFunc(X, y, parameters):\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 \n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "    \n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] < 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.867564534231\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predictFunc(X_train.astype(float), Y_train.astype(float), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTest(X, parameters):\n",
    "    m = 1309-892+1\n",
    "    n = len(parameters)//2\n",
    "    p = np.zeros((1,m))\n",
    "    probas, caches = L_model_forward(X[1:,:], parameters)\n",
    "    \n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] < 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    return p\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTest = predictTest(test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 418)\n"
     ]
    }
   ],
   "source": [
    "print(predictionTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('submission.csv', 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
    "    spamwriter.writerow(['PassengerId', 'Survived'])\n",
    "    for i in range(892, 1310): \n",
    "        spamwriter.writerow([str(i), str(int(predictionTest[0][i-892]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
